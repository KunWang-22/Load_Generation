{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 22\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/UKDA_2013_clean.csv\"\n",
    "original_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_num = 10\n",
    "aggregated_data = pd.DataFrame()\n",
    "aggregated_data[\"time\"] = pd.to_datetime(original_data[\"time\"])\n",
    "for i in range((original_data.shape[1]-2)//aggregation_num):\n",
    "    temp_data = original_data.iloc[:, (1+i*aggregation_num):(1+(i+1)*aggregation_num)].sum(axis=1)\n",
    "    temp_name = \"user_\" + str(i+1)\n",
    "    aggregated_data[temp_name] = temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data[\"month\"] = [aggregated_data[\"time\"][i].month for i in range(aggregated_data.shape[0])]\n",
    "aggregated_data[\"day\"] = [aggregated_data[\"time\"][i].day for i in range(aggregated_data.shape[0])]\n",
    "aggregated_data[\"hour\"] = [aggregated_data[\"time\"][i].hour for i in range(aggregated_data.shape[0])]\n",
    "aggregated_data[\"minute\"] = [aggregated_data[\"time\"][i].minute for i in range(aggregated_data.shape[0])]\n",
    "month_index = aggregated_data[\"month\"].value_counts(sort=False)//48\n",
    "\n",
    "condition_data = pd.DataFrame()\n",
    "condition_data[\"time\"] = aggregated_data[\"time\"]\n",
    "condition_df = aggregated_data.groupby([\"month\", \"day\", \"hour\", \"minute\"]).agg(\"mean\").round(3)\n",
    "for user in aggregated_data.columns[1:-4]:\n",
    "    user_data = np.array([])\n",
    "    for month in month_index.index:\n",
    "        days = month_index[month]\n",
    "        temp_data = condition_df[user].loc[month, 14, :, :].values.reshape(1,-1)\n",
    "        month_data = temp_data.repeat(days, axis=0)\n",
    "        user_data = np.append(user_data, month_data.flatten())\n",
    "    condition_data[user] = user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = aggregated_data.iloc[:, 1:-4].values.T.reshape(-1,48)\n",
    "condition = condition_data.iloc[:, 1:].values.T.reshape(-1,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29930, 48)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8190, 3.3720, 2.8270,  ..., 5.4070, 4.9140, 5.0400],\n",
       "        [4.8250, 3.6840, 2.6820,  ..., 4.8540, 4.5340, 4.5870],\n",
       "        [2.5680, 2.4770, 2.4180,  ..., 4.0810, 3.4280, 3.5900],\n",
       "        ...,\n",
       "        [2.3260, 2.2620, 1.2240,  ..., 2.2090, 2.3060, 1.8340],\n",
       "        [1.4660, 1.5350, 1.7180,  ..., 2.1710, 1.9040, 1.9230],\n",
       "        [1.2420, 1.1930, 0.8510,  ..., 1.7180, 1.5670, 1.3540]])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(origin).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_UKDA(Dataset):\n",
    "    def __init__(self, file_path, aggregation_num):\n",
    "        origin, condition = get_dataset(file_path, aggregation_num)\n",
    "        self.origin = torch.from_numpy(origin).type(torch.float32).unsqueeze(-1)\n",
    "        self.condition = torch.from_numpy(condition).type(torch.float32).unsqueeze(-1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.origin[index], self.condition[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.origin.shape[0]\n",
    "\n",
    "\n",
    "def get_dataset(file_path, aggregation_num):\n",
    "    original_data = pd.read_csv(file_path)\n",
    "\n",
    "    aggregated_data = pd.DataFrame()\n",
    "    aggregated_data[\"time\"] = pd.to_datetime(original_data[\"time\"])\n",
    "    for i in range((original_data.shape[1]-2)//aggregation_num):\n",
    "        temp_data = original_data.iloc[:, (1+i*aggregation_num):(1+(i+1)*aggregation_num)].sum(axis=1)\n",
    "        temp_name = \"user_\" + str(i+1)\n",
    "        aggregated_data[temp_name] = temp_data\n",
    "\n",
    "    aggregated_data[\"month\"] = [aggregated_data[\"time\"][i].month for i in range(aggregated_data.shape[0])]\n",
    "    aggregated_data[\"day\"] = [aggregated_data[\"time\"][i].day for i in range(aggregated_data.shape[0])]\n",
    "    aggregated_data[\"hour\"] = [aggregated_data[\"time\"][i].hour for i in range(aggregated_data.shape[0])]\n",
    "    aggregated_data[\"minute\"] = [aggregated_data[\"time\"][i].minute for i in range(aggregated_data.shape[0])]\n",
    "    month_index = aggregated_data[\"month\"].value_counts(sort=False)//48\n",
    "\n",
    "    condition_data = pd.DataFrame()\n",
    "    condition_data[\"time\"] = aggregated_data[\"time\"]\n",
    "    condition_df = aggregated_data.groupby([\"month\", \"day\", \"hour\", \"minute\"]).agg(\"mean\").round(3)\n",
    "    for user in aggregated_data.columns[1:-4]:\n",
    "        user_data = np.array([])\n",
    "        for month in month_index.index:\n",
    "            days = month_index[month]\n",
    "            temp_data = condition_df[user].loc[month, 14, :, :].values.reshape(1,-1)\n",
    "            month_data = temp_data.repeat(days, axis=0)\n",
    "            user_data = np.append(user_data, month_data.flatten())\n",
    "        condition_data[user] = user_data\n",
    "\n",
    "    origin = aggregated_data.iloc[:, 1:-4].values.T.reshape(-1,48)\n",
    "    condition = condition_data.iloc[:, 1:].values.T.reshape(-1,48)\n",
    "\n",
    "    return origin, condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"../data/UKDA_2013_clean.csv\"\n",
    "test_dataset = Dataset_UKDA(test_path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48, 1])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = original_data.iloc[:, 1:3].values.T.reshape(-1,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 48)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timestep_Embedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(Timestep_Embedding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.fc_1 = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.fc_2 = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.activation = nn.SiLU()\n",
    "\n",
    "    def forward(self, t):\n",
    "        x = self._embedding(t)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "    def _embedding(self, t):\n",
    "        t_seq = t.repeat(1, self.embedding_dim//2)\n",
    "        frequency = torch.pow(10, torch.arange(self.embedding_dim//2) / (self.embedding_dim//2-1) * 4.0)\n",
    "        emb_sin = torch.sin(t_seq * frequency)\n",
    "        emb_cos = torch.cos(t_seq * frequency)\n",
    "        embedding = torch.cat([emb_sin, emb_cos], dim=1)\n",
    "        return embedding\n",
    "\n",
    "def timestep_sample(noise_step, n):\n",
    "    # 采样n个timestep用于训练模型，采用均匀分布\n",
    "    time_steps = torch.randint(1, noise_step, (n,1))\n",
    "    return time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1]), torch.Size([10, 32]))"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_timestep = timestep_sample(50, 10)\n",
    "test_timestep_embedding = Timestep_Embedding(32)\n",
    "test_timestep_emb = test_timestep_embedding(test_timestep)\n",
    "test_timestep.shape, test_timestep_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PE_Embedding(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super(PE_Embedding, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.fc = nn.Linear(self.input_dim, self.embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        data_length = x.shape[1]\n",
    "        x = self.fc(x)\n",
    "        x = x + self._position_encoding(data_length)\n",
    "        return x\n",
    "\n",
    "    def _position_encoding(self, data_length):\n",
    "        encoding = torch.zeros((data_length, self.embedding_dim))\n",
    "        position = torch.arange(data_length).unsqueeze(1)\n",
    "        encoding[:, 0::2] = torch.sin( position / torch.pow(10000, torch.arange(0, self.embedding_dim, 2)/self.embedding_dim) )\n",
    "        encoding[:, 1::2] = torch.cos( position / torch.pow(10000, torch.arange(1, self.embedding_dim, 2)/self.embedding_dim) )\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48, 32])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data = torch.randn((4,16, 1))\n",
    "test_data, test_condition = test_dataset[:10]\n",
    "test_pe_embedding = PE_Embedding(1, 32)\n",
    "test_pe_emb = test_pe_embedding(test_data)\n",
    "test_pe_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Layer(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_head, dropout):\n",
    "        super(Encoder_Layer, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_head, dropout=dropout)\n",
    "        self.fc_1 = nn.Linear(self.embedding_dim, self.embedding_dim//2)\n",
    "        self.fc_2 = nn.Linear(self.embedding_dim//2, self.embedding_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer_norm_1 = nn.LayerNorm(self.embedding_dim)\n",
    "        self.layer_norm_2 = nn.LayerNorm(self.embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x, _ = self.attention(query=x, key=x, value=x)\n",
    "        x = self.layer_norm_1(x+residual)\n",
    "        residual = x\n",
    "        x = self.fc_1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.layer_norm_2(x+residual)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 32])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encoder = Encoder_Layer(32, 2, 0.3)\n",
    "test_attention = test_encoder(test_pe_emb)\n",
    "test_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Condition_Embedding(nn.Module):\n",
    "    def __init__(self, condition_input_dim, embedding_dim, num_head, num_layer, dropout=0.2):\n",
    "        super(Condition_Embedding, self).__init__()\n",
    "        self.pe_embedding = PE_Embedding(condition_input_dim, embedding_dim)\n",
    "        self.encoder = nn.ModuleList([Encoder_Layer(embedding_dim, num_head, dropout) for _ in range(num_layer)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pe_embedding(x)\n",
    "        for encoder_layer in self.encoder:\n",
    "            x = encoder_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 48, 1]), torch.Size([10, 48, 32]))"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_condition_embedding = Condition_Embedding(1, 32, 2, 4, 0.2)\n",
    "test_condition_emb = test_condition_embedding(test_condition)\n",
    "test_condition.shape, test_condition_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Block(nn.Module):\n",
    "    def __init__(self, condition_input_dim, embedding_dim, num_head, num_layer, dropout):\n",
    "        super(Residual_Block, self).__init__()\n",
    "        self.fc_timestep = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.fc_condition = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.fc_output = nn.Linear(embedding_dim//2, embedding_dim)\n",
    "        self.attention = nn.ModuleList([Encoder_Layer(embedding_dim, num_head, dropout) for _ in range(num_layer)])\n",
    "        self.condtion_embbeding = Condition_Embedding(condition_input_dim, embedding_dim, num_head, num_layer, dropout)\n",
    "\n",
    "    def forward(self, x, timestep_emb, condition):\n",
    "        residual = x\n",
    "        x = x + self.fc_timestep(timestep_emb.unsqueeze(1))\n",
    "        for attention_layer in self.attention:\n",
    "            x = attention_layer(x)\n",
    "        \n",
    "        condition_emb = self.condtion_embbeding(condition)\n",
    "        x = x + self.fc_condition(condition_emb)\n",
    "        \n",
    "        x_1, x_2 = torch.chunk(x, 2, dim=-1)\n",
    "        x = torch.sigmoid(x_1) * torch.tanh(x_2)\n",
    "        x = self.fc_output(x)\n",
    "        residual = residual + x\n",
    "\n",
    "        return residual, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 48, 32]), torch.Size([10, 48, 32]))"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_residual_block = Residual_Block(1, 32, 2, 4, 0.2)\n",
    "test_residual, test_skip = test_residual_block(test_pe_emb, test_timestep_emb, test_condition)\n",
    "test_residual.shape, test_skip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, condition_input_dim, embedding_dim, num_head, num_layer, num_block, dropout):\n",
    "        super(Model, self).__init__()\n",
    "        self.pe_embedding = PE_Embedding(input_dim, embedding_dim)\n",
    "        self.timestep_embedding = Timestep_Embedding(embedding_dim)\n",
    "        self.residual_model = nn.ModuleList([Residual_Block(condition_input_dim, embedding_dim, num_head, num_layer, dropout) for _ in range(num_block)])\n",
    "        # check dim !!!\n",
    "        self.fc_input = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.fc_concat = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.fc_output = nn.Linear(embedding_dim, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, timestep, conditon):\n",
    "        timestep_emb = self.timestep_embedding(timestep)\n",
    "        \n",
    "        x = self.pe_embedding(x)\n",
    "        x = self.fc_input(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        skip = []\n",
    "        for residual_layer in self.residual_model:\n",
    "            x, skip_output = residual_layer(x, timestep_emb, conditon)\n",
    "            skip.append(skip_output)\n",
    "\n",
    "        x = torch.sum(torch.stack(skip), dim=0)\n",
    "        x = self.fc_concat(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc_output(x)\n",
    "\n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48, 1])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = Model(1, 1, 32, 2, 4, 4, 0.2)\n",
    "test_noise_predicted = test_model(test_data, test_timestep, test_condition)\n",
    "test_noise_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion():\n",
    "    def __init__(self, noise_step, beta_start, beta_end, data_length, device):\n",
    "        self.noise_step = noise_step\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.data_length = data_length\n",
    "        self.device = device\n",
    "        # 定义beta和对应的alpha\n",
    "        self.beta = self.noise_schedule().to(self.device)\n",
    "        self.alpha = 1 - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "    def noise_schedule(self):\n",
    "        betas = torch.linspace(self.beta_start, self.beta_end, self.noise_step)\n",
    "        return betas\n",
    "\n",
    "    def forward_process(self, x_0, t):\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1-self.alpha_hat[t])\n",
    "        #重参数技巧，通过正态分布采样然后变换得到加噪后的分布\n",
    "        noise = torch.randn_like(x_0)\n",
    "        x_t = sqrt_alpha_hat * x_0 + sqrt_one_minus_alpha_hat * noise\n",
    "        return x_t, noise\n",
    "    \n",
    "    def timestep_sample(self, n):\n",
    "        # 采样n个timestep用于训练模型，采用均匀分布\n",
    "        time_steps = torch.randint(1, self.noise_step, (n,1))\n",
    "        return time_steps\n",
    "\n",
    "    def sample(self, model, n, condition):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n, self.data_length)).unsqueeze(-1).to(self.device)\n",
    "            for i in reversed(range(1, self.noise_step)):\n",
    "                t = (torch.ones(n)*i).long().unsqueeze(-1).to(self.device)\n",
    "                # conditional sample\n",
    "                predicted_noise = model(x, t, condition)\n",
    "                alpha_t = self.alpha[t].unsqueeze(-1)\n",
    "                alpha_hat_t = self.alpha_hat[t].unsqueeze(-1)\n",
    "                # beta此处对应方差，也可以用beta_tilde表示\n",
    "                beta_t = self.beta[t].unsqueeze(-1)\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                x = 1 / torch.sqrt(alpha_t) * (x - (1-alpha_t)/torch.sqrt(1-alpha_hat_t) * predicted_noise) + torch.sqrt(beta_t) * noise\n",
    "        model.train()\n",
    "        # 此处可以根据数据情况，考虑是否添加数据归一化/反归一化的操作\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 1])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_diffusion = Diffusion(50, 0.0001, 0.2, 48, None)\n",
    "_, test_noise = test_diffusion.forward_process(test_data[0], test_timestep[0])\n",
    "test_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48, 1])"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_diffusion.sample(test_model, 10, test_condition).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_timestep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bf39c0c4fbe23f7443ef2e90fa4c9adbc082ff301d49d14ae3acc5df81e7740"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
